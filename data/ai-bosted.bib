@InProceedings{10.1007/978-3-031-80946-0_1,
author="Guti{\'e}rrez-Navarro, Juan
and Mora-S{\'a}nchez, {\'A}ngel
and Rodr{\'i}guez-Jim{\'e}nez, Silvia
and Blanco-Murillo, J.L.",
editor="Marreiros, Goreti
and Grande, Laura
and Llerena, Juan Pedro
and Concei{\c{c}}{\~a}o, Lu{\'i}s
and Ko, Hoon
and Plaza, Marta
and Ricca, Michela",
title="AI-Boosted Video Annotation: Exploring Pre-Labeling withÂ Cross-Modalities",
booktitle="Distributed Computing and Artificial Intelligence, Special Sessions II, 21st International Conference",
year="2025",
publisher="Springer Nature Switzerland",
address="Cham",
pages="5--15",
abstract="Annotation in large-scale video datasets requires significant resources. To enhance the efficiency of this process, we suggest employing pre-trained cross-modal models within the Human-in-the-Loop (HITL) paradigm. We used a synthetic video dataset to generate precise semantic annotations and assess the effectiveness of different label representations in comprehending visual information across diverse vision tasks, including fine- and coarse-grained ones. We also introduce a framework for automating pre-annotation extraction from semantically similar frames. Our approach presents promising avenues for efficiently annotating video data, crucial for developing robust Machine Learning (ML) systems.",
isbn="978-3-031-80946-0"
}

