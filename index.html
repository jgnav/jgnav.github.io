<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script async defer src="https://buttons.github.io/buttons.js"></script>

  <title>Juan Guti√©rrez</title>

  <meta name="author" content="Juan Guti√©rrez">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<script>
  const authorURLs = {
    mateoCamara: "https://mateocamara.com/",
    joseLuisBlanco: "https://portalcientifico.upm.es/es/ipublic/researcher/309256",
    victorGutierrez: "https://vgutierrez2404.github.io/"
  };
</script>



<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Juan Guti√©rrez</name>
                  </p>
                  <p style="text-align:center">
                    Email: <a href="mailto:juan.gutierrez@upm.es">juan.gutierrez [at] upm [dot] es</a>
                  <p>
                    I am a Ph.D student in Computer Vision at <a href="https://www.upm.es/">UPM</a>, supervised by <a
                      class="author-joseluis">Dr. Jos√© Luis Blanco
                      Murillo</a>, and, since September 2022, member of <a href="https://www.gaps.ssr.upm.es/">GAPS</a> research group.
                  </p>
                  <p style="text-align:center">

                    
                    <a href="data/Resume_JG.pdf">Resume</a>
                    &nbsp; | &nbsp;
                    <a href="https://scholar.google.es/citations?user=wT7WzX8AAAAJ&hl=es&authuser=1">Scholar</a>
                    &nbsp; | &nbsp;
                    <a href="https://github.com/jgnav">GitHub</a>
                    &nbsp; | &nbsp;
                    <a href="https://www.researchgate.net/profile/Juan-Gutierrez-178">ResearchGate</a>
                    &nbsp; | &nbsp;
                    <a href="https://orcid.org/0009-0001-6827-5153">ORCID</a>
                    &nbsp; | &nbsp;
                    <a href="https://www.linkedin.com/in/juan-gutierrez-navarro/">LinkedIn</a>
                    &nbsp; | &nbsp;
                    <a href="https://x.com/jgnav_">X</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/juangutierrez.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/juangutierrez_circle.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in the principles of self-supervised representation learning for image and video
                    foundation models, aiming to construct latent spaces that robustly encode semantics and
                    spatiotemporal dynamics. I leverage the geometry of the resulting feature manifold to analyze data
                    structure and propagate sparse relational supervision. Some papers are <span
                      class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr onmouseout="panc_stop()" onmouseover="panc_start()" bgcolor="#ffffd0">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='panc_image' style="background-color:#ffffd0;">
                      <img src='images/panc_after.png' width=100% alt="PANC visualization">
                    </div>
                    <img src='images/panc_before.png' width=100% alt="PANC placeholder">
                  </div>
                  <script type="text/javascript">
                    function panc_start() {
                      document.getElementById('panc_image').style.opacity = "1";
                    }
                    function panc_stop() {
                      document.getElementById('panc_image').style.opacity = "0";
                    }
                    panc_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="data/panc.pdf">
                    <span class="papertitle">PANC: Prior-Aware Normalized Cut for Object Segmentation</span>
                  </a>
                  <br>
                  <strong>Juan Guti√©rrez</strong>,
                  <a class="author-victor">V√≠ctor Guti√©rrez</a>,
                  <a class="author-joseluis">Jos√© Luis Blanco</a>
                  <br>
                  <em>Preprint</em>, 2026
                  <br>
                  <a href="data/panc.pdf">pdf</a> 
                  <!-- | <a href="javascript:void(0)" class="bibtex-link" onclick="showBibtexModal('data/panc.bib')">bibtex</a> -->
                  <p></p>
                  <p>
                    A weakly-supervised spectral segmentation framework using minimal annotated visual tokens to produce stable, controllable object masks.
                  </p>
                </td>
              </tr>


                <tr onmouseout="hitl_stop()" onmouseover="hitl_start()" bgcolor="#ffffd0">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='hitl_image' style="background-color:#ffffd0;">
                      <img src='images/hitl_after.png' width=100% alt="HITL visualization">
                    </div>
                    <img src='images/hitl_before.png' width=100% alt="HITL placeholder">
                  </div>
                  <script type="text/javascript">
                    function hitl_start() {
                      document.getElementById('hitl_image').style.opacity = "1";
                    }
                    function hitl_stop() {
                      document.getElementById('hitl_image').style.opacity = "0";
                    }
                    hitl_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="data/hitl.pdf">
                    <span class="papertitle">An Evaluation of Hybrid Annotation Workflows on High-Ambiguity Spatiotemporal Video Footage</span>
                  </a>
                  <br>
                  <strong>Juan Guti√©rrez</strong>,
                  <a class="author-victor">V√≠ctor Guti√©rrez-Garc√≠a</a>,
                  √Ångel Mora-S√°nchez,
                  Silvia Rodr√≠guez-Jim√©nez,
                  <a class="author-joseluis">Jos√© Luis Blanco-Murillo</a>
                  <br>
                  <em>Preprint</em>, 2026
                  <br>
                  <a href="data/hitl.pdf">pdf</a> 
                  <!-- | <a href="javascript:void(0)" class="bibtex-link" onclick="showBibtexModal('data/hitl.bib')">bibtex</a> -->
                  <p></p>
                  <p>
                    Benchmarking assisted annotation workflows using fine-tuned vision-language model for video.
                  </p>
                </td>
              </tr>


            <tr onmouseout="speech_stop()" onmouseover="speech_start()">
                  <td style="padding:16px;width:20%;vertical-align:middle">
                    <div class="one">
                      <div class="two" id='speech_image'>
                        <img src='images/euronoise_after.png' width=100% alt="Speech visualization">
                      </div>
                      <img src='images/euronoise_before.png' width=100% alt="Speech placeholder">
                    </div>
                    <script type="text/javascript">
                      function speech_start() {
                        document.getElementById('speech_image').style.opacity = "1";
                      }
                      function speech_stop() {
                        document.getElementById('speech_image').style.opacity = "0";
                      }
                      speech_stop()
                    </script>
                  </td>
                  <td style="padding:8px;width:80%;vertical-align:middle">
                    <a href="https://arxiv.org/abs/2507.02530">
                      <span class="papertitle">Open-Source System for Multilingual Translation and Cloned Speech
                        Synthesis</span>
                    </a>
                    <br>
                    <a class="author-mateo">Mateo C√°mara</a>,
                    <strong>Juan Guti√©rrez</strong>,
                    Mar√≠a Pilar Daza,
                    <a class="author-joseluis">Jos√© Luis Blanco</a>
                    <br>
                    <em>Forum Acusticum / Euronoise 2025</em>, M√°laga, Spain
                    <br>
                    <a href="https://arxiv.org/abs/2507.02530">arXiv</a> |
                    <a href="javascript:void(0)" class="bibtex-link" onclick="showBibtexModal('data/euronoise.bib')">bibtex</a>
                    <p></p>
                    <p>
                      An open-source pipeline combining speech recognition, LLM-based translation, and voice-cloning TTS for real-time multilingual communication.
                    </p>
                  </td>
                </tr>


              <tr onmouseout="dcai_stop()" onmouseover="dcai_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='dcai_image'>
                      <img src='images/dcai_after.png' width=100% alt="DCAI visualization">
                    </div>
                    <img src='images/dcai_before.png' width=100% alt="DCAI placeholder">
                  </div>
                  <script type="text/javascript">
                    function dcai_start() {
                      document.getElementById('dcai_image').style.opacity = "1";
                    }
                    function dcai_stop() {
                      document.getElementById('dcai_image').style.opacity = "0";
                    }
                    dcai_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-80946-0_1">
                    <span class="papertitle">AI-Boosted Video Annotation: Exploring Pre-Labeling with
                      Cross-Modalities</span>
                  </a>
                  <br>
                  <strong>Juan Guti√©rrez</strong>,
                  √Ångel Mora S√°nchez,
                  Silvia Rodr√≠guez Jim√©nez,
                  <a class="author-joseluis">Jos√© Luis Blanco</a>
                  <br>
                  <em>Distributed Computing and Artificial Intelligence (DCAI)</em>, 2024 (Springer LNCS, 2025)
                  <br>
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-80946-0_1">springer</a> |
                  <a href="javascript:void(0)" class="bibtex-link" onclick="showBibtexModal('data/dcai.bib')">bibtex</a>
                  <p></p>
                  <p>
                    Leveraging pre-trained cross-modal models within the Human-in-the-Loop paradigm to efficiently pre-annotate large-scale video datasets.
                  </p>
                </td>
              </tr>



              <tr onmouseout="thesis_stop()" onmouseover="thesis_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='thesis_image'>
                      <img src='images/thesis_after.png' width=100%>
                    </div>
                    <img src='images/thesis_before.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function thesis_start() {
                      document.getElementById('thesis_image').style.opacity = "1";
                    }
                    function thesis_stop() {
                      document.getElementById('thesis_image').style.opacity = "0";
                    }
                    thesis_stop()
                  </script>
                </td>

                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://oa.upm.es/75341/">
                    <span class="papertitle">A Study on the Development of a Video Annotation Support System Using an Image- and Text-Agnostic Model</span>
                  </a>
                  <br>
                  <strong>Juan Guti√©rrez</strong>
                  <br>
                  <em>Master's Thesis</em>, UPM, 2023
                  <br>
                  <a href="https://oa.upm.es/75341/">thesis</a> |
                  <a href="javascript:void(0)" class="bibtex-link" onclick="showBibtexModal('data/masterthesis.bib')">bibtex</a>

                  <p></p>
                  <p>
                    Developed a CLIP-based human-in-the-loop system for efficient video annotation via keyframe
                    selection, semantic retrieval, and automatic label propagation.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>







          <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:6px;">
            <tbody>
              <tr>
                <td>
                  <h2>Miscellanea</h2>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%; border:0px; border-spacing:16px; border-collapse:separate; margin-right:auto; margin-left:auto;">
            <tbody>

              <tr>
                <td align="center"
                  style="background-color: #edd892; border-radius: 12px; width:20%; vertical-align:middle; padding:16px;">
                  <h2 style="margin:0; color: #333;">Teaching</h2>
                </td>

                <td style="padding:8px; width:80%; vertical-align:middle;">
                  <strong>Teaching Assistant</strong>
                  <br>
                  - Design of Communications Systems and Equipment (M.S in Signal Theory and Communications, 1st course, UPM)
                  <br>
                  - Computing and Visualization Tools (B.S in Telecommunication Engineering, 2nd course, UPM)
                  <br>
                  <br>
                  <strong>Thesis Supervisor</strong>
                  <br>
                  - Supervised two M.S. and two B.S. theses
                </td>
              </tr>

              <tr>
                <td align="center"
                  style="background-color: #aaba9e; border-radius: 12px; width:20%; vertical-align:middle; padding:16px;">
                  <h2 style="margin:0; color: #333;">Talks</h2>
                </td>

                <td style="padding:8px; width:80%; vertical-align:middle;">
                  - Text-Based Video Retrieval through Hierarchical Content Representation (Great Talks @ Teleco, 2025,
                  Madrid, Spain)
                  <br>
                  - Using Agnostic Models on Image and Text to Support Video Annotation (AIAI 2023, Le√≥n, Spain)
                </td>
              </tr>

              <tr>
                <td align="center"
                  style="background-color: #b8c4d4; border-radius: 12px; width:20%; vertical-align:middle; padding:16px;">
                  <h2 style="margin:0; color: #333;">Short Papers</h2>
                </td>

                <td style="padding:8px; width:80%; vertical-align:middle;">
                   <a href="https://www.min-eng.com/comminution25/drafts/session2/asbjornsson.pdf">Data Integration and Analytics of Cone Crusher Responses</a>
                  <br>
                  G. Asbj√∂rnsson, M. Evertsson, P. Plaza, S. Rodr√≠guez-Jim√©nez, J. Gavilanes, J. Cort√≥n-Gonz√°lez, <strong>Juan Guti√©rrez</strong>, J. L. Blanco, J. E. Ortiz
                  <br>
                  <em>14th International Comminution Symposium (Comminution '25)</em>, Cape Town, 2025
                </td>
              </tr>

            </tbody>
          </table>




          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <hr />
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="2">
                    Last update: February 2026
                </p>
              </td>
            </tr>
          </table>


        </td>
      </tr>
  </table>
<!-- BibTeX Modal -->
<div id="bibtex-overlay" class="bibtex-overlay">
  <div class="bibtex-modal">
    <div class="bibtex-modal-header">
      <h3>BibTeX Citation</h3>
      <button class="bibtex-close" onclick="closeBibtexModal()">&times;</button>
    </div>
    <pre id="bibtex-content" class="bibtex-content"></pre>
    <button class="bibtex-copy-btn" onclick="copyBibtex()">Copy to Clipboard</button>
  </div>
</div>

<script>
  document.querySelectorAll('.author-mateo').forEach(el => el.href = authorURLs.mateoCamara);
  document.querySelectorAll('.author-joseluis').forEach(el => el.href = authorURLs.joseLuisBlanco);
  document.querySelectorAll('.author-victor').forEach(el => el.href = authorURLs.victorGutierrez);

  // BibTeX Modal Functions
  function showBibtexModal(bibPath) {
    fetch(bibPath)
      .then(response => response.text())
      .then(data => {
        document.getElementById('bibtex-content').textContent = data.trim();
        document.getElementById('bibtex-overlay').classList.add('active');
      })
      .catch(error => {
        console.error('Error loading BibTeX:', error);
        alert('Error loading BibTeX file');
      });
  }

  function closeBibtexModal() {
    document.getElementById('bibtex-overlay').classList.remove('active');
    const copyBtn = document.querySelector('.bibtex-copy-btn');
    copyBtn.textContent = 'Copy to Clipboard';
    copyBtn.classList.remove('copied');
  }

  function copyBibtex() {
    const bibtexText = document.getElementById('bibtex-content').textContent;
    navigator.clipboard.writeText(bibtexText).then(() => {
      const copyBtn = document.querySelector('.bibtex-copy-btn');
      copyBtn.textContent = 'Copied!';
      copyBtn.classList.add('copied');
      setTimeout(() => {
        copyBtn.textContent = 'Copy to Clipboard';
        copyBtn.classList.remove('copied');
      }, 2000);
    }).catch(err => {
      console.error('Failed to copy:', err);
      alert('Failed to copy to clipboard');
    });
  }

  // Close modal when clicking outside
  document.getElementById('bibtex-overlay').addEventListener('click', function(e) {
    if (e.target === this) {
      closeBibtexModal();
    }
  });

  // Close modal with Escape key
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape') {
      closeBibtexModal();
    }
  });
</script>
</body>

</html>
